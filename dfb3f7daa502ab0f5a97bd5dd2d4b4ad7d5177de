{
  "comments": [
    {
      "key": {
        "uuid": "e26949b7_c12ceb8e",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1145459
      },
      "writtenOn": "2020-09-11T15:17:54Z",
      "side": 1,
      "message": "In hindsight I probably should not have opened another CL for the storage leak? In any case, the comments on 2386332 really should be on this CL so copying and pasting them here (includin your response). Dunno if there\u0027s a better way to do this. Sorry for the noise.\n\nPhew! That was an education! I had never really looked at the compiler, deoptimizer, etc. so it took a bit of time to work this out. I spent a day staring at code talking about OSR before I figured out what OSR stood for. In any case...\n\nI think we can get a deopt even for code we don\u0027t know about because let\u0027s say you have an OSR (only) optimized function. Now let\u0027s say you start a profiler. The profiler starts by adding information about all known compilations to the profiler code map using a list built by EnumerateCompiledFunctions (in log.cc). That code has the following:\n\n \n    if (obj.IsSharedFunctionInfo()) {\n      SharedFunctionInfo sfi \u003d SharedFunctionInfo::cast(obj);\n      if (sfi.is_compiled() \u0026\u0026 !sfi.IsInterpreted()) {\n        AddFunctionAndCode(sfi, AbstractCode::cast(sfi.abstract_code()), sfis,\n                           code_objects, compiled_funcs_count);\n        ++compiled_funcs_count;\n      }\n    } else if (obj.IsJSFunction()) {\n      // Given that we no longer iterate over all optimized JSFunctions, we need\n      // to take care of this here.\n      JSFunction function \u003d JSFunction::cast(obj);\n      // TODO(jarin) This leaves out deoptimized code that might still be on the\n      // stack. Also note that we will not log optimized code objects that are\n      // only on a type feedback vector. We should make this mroe precise.\n      if (function.HasAttachedOptimizedCode() \u0026\u0026\n          Script::cast(function.shared().script()).HasValidSource()) {\n        AddFunctionAndCode(function.shared(),\n                           AbstractCode::cast(function.code()), sfis,\n                           code_objects, compiled_funcs_count);\n        ++compiled_funcs_count;\n      }\n    }\nSo when we hit the sfi for our OSR optimized function it will still have IsInterpreted set since it has not been optimized in native context so that will prevent the code from being logged. When we hit the function, HasAttachedOptimizedCode won\u0027t be set so that will also prevent the OSR optimized code from being sent.\n\nA comment about the TODO comment. Was that perhaps meant to say \"leaves out (OSR) optimized code\"? Because the code certainly leaves that out and don\u0027t think it matters (at least to the sampler/profiler) if the code is not optimized, right? \n\nIn any case, later, when the OSR code is deoptimized we end up sending the deopt event to the sampling thread which knows nothing about that code so (before my fix) would end up orphaning the deopt_frames causing a storage leak. The deopt in my test code is obvious in hindsight -- I had function statements in the global context which ended up putting the function names on the global object which would then get replaced by the other threads\u0027 equivalent function statements, forcing the earlier compilations to be deoptimized because the functions the were calling (via global properties) were now change -- really they were the same code but different function instances. I hadn\u0027t meant to do this and, in hindsight, it\u0027s not very clever.\n\nIMO, ideally the above code in EnumerateCompiledFunctions would also log OSR compilations. I wrote a test case where I started a profiler after a function still on the stack had been OSR optimized. I then let that function go to town burning CPU and when profiler was stopped, sure enough, there were no samples inside the OSR optimized code, even though that\u0027s where we had spent 99.99% of our time -- the samples all attributed ticks to the OSR optimized function caller.\n\nThe problem, of course, is that it\u0027s fairly expensive to find OSR code as there are no references to it in either the function or sfi heap objects. I guess one solution might be for the logging code to loop over the the optimized function hash table (talking a bit out of my hat, here) and pick out the OSR optimized functions. Another would be to maintain an array of OSR optimizations in the sfi (the array pointer would normally be the hole). While this probably would have pretty low overhead, even that little overhead might be considered too much for something that\u0027s just there for oddball profiler cases. Then again, it might be useful to have such an array to quickly find any OSRs for an sfi that gets deoptimized (more talking out of my hat). \n\nOr we could just shrug and say \"shame on you\" if you start profiling while in the middle of an OSR compiled (so intensive) function -- you won\u0027t see the insides of that function in the profile. I\u0027m OK with this and any other change would certainly be non-trivial and should be made with another CL (I\u0027m not necessarily volunteering ;-)), \n\nWhat I would propose to do in the short term is:\n1. Add the storage leak fix to this CL.\n2. Fix up my test to not drive the storage leak code. This only happened by accident and, in fact, my code is a bit brain-dead about really driving multi-threading (it barely does). In fact, if it had been less brain-dead, it wouldn\u0027t have hit the storage leak issue.\n3. Add another test to drive the storage leak code with 100% reliability. No multi-threading or multiple profilers required. This might be overkill as that return in CodeDeoptEventRecord::UpdateCodeMap without deleting deopt_frames is so clearly wrong it\u0027s not like someone would ever decide to undo my change. But I\u0027ll trust your judgment.\n\nAnother little yucky thing I noticed was that the above logging code would often log the same code multiple times since it would log it once for the sfi and then every function instance that uses that sfi. Seems like it would be trivial to check if function.code() is the same as function.shared().abstract_code() to avoid this (I assume they can be different for maybe a deopt/reopt on the sfi?). Obviously, we would always encounter a function\u0027s sfi in our heap walk.\n\nOne last thing bothered me in my research was the zombie OSR optimized code that survived after it was no longer on the stack. I guess that in general compiled code is not collected in V8 (right?) so one wouldn\u0027t be able to recover the storage for the code (unless it\u0027s at the end of the code space?). But it seems that it would be nice to at least make it invisible to everything thing else after it\u0027s no longer on the stack. Conceptually, it seems straightforward -- after compilation find the outermost stack level where the OSR compiled function appears and stick some cleanup code before that stack level is exited. But, this might end up getting into platform-specific code so have an extra order of difficulty. Presumably there has to be some stack-walk and fixup after an OSR compile. In any case, not an area I know anything about so I\u0027m probably dead wrong about both my observation that a zombie OSR has no use and that it could/should be easily cleaned up. Still, to me it felt yucky, especially given the stack walk. Hmm.. wonder which stack it walks in a multi-threading environment :-O.\n\nSorry for the long note but it seems hard to explain the issue(s)in fewer words and I also want to make sure as much as possible that I understand sufficiently to not be band-aiding code.",
      "revId": "dfb3f7daa502ab0f5a97bd5dd2d4b4ad7d5177de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f7faaca6_76cb075b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1145459
      },
      "writtenOn": "2020-09-11T15:21:50Z",
      "side": 1,
      "message": "Arghh, making a bit of a mess with the comments here, sorry. I think I\u0027m starting to understand how this UI works. In any case, a copy of your comments from 2386332:\n\nPeter Marshall:\n\nWow, thanks for the investigation and write-up!\n\n1. Add the storage leak fix to this CL.\n\nSounds good to me\n\n3. Add another test to drive the storage leak code with 100% reliability. No multi-threading or multiple profilers required\n\nThat would be great if you can add this test to this CL as well. It\u0027s not your bug so I don\u0027t expect you to go overboard here, if you can write this test reasonably easily then that\u0027s great. If not I can take a look.\n\n2. Fix up my test to not drive the storage leak code.\n\nThat sounds good. There is one other problem I noticed with your test (my bad, missed this when reviewing). Each profile you start should use a different name, otherwise they are ignored - see https://source.chromium.org/chromium/chromium/src/+/master:v8/src/profiler/profile-generator.cc;l\u003d764;drc\u003dc741e070dbfcc33b2369e7a5131be87c7b21bb99\n\nRe. the zombie OSR code - I\u0027m not sure what the retention mechanism is for OSR code. Attaching it to the SFI/JSFunction would keep it alive which is why we don\u0027t do that I guess. Let me look into that further but we don\u0027t need to block on it for this work.\n\nVery interesting finding that we don\u0027t log creation of OSR code and that you can reproduce a lack of tick in a test case. We should definitely look at fixing that as it is probably essential for some sorts of workloads. I guess this only applies to code where the interpreted bytecode is created before profiling, and the OSR happens after profiling starts? I will take a look at this, thanks for the bug report.",
      "revId": "dfb3f7daa502ab0f5a97bd5dd2d4b4ad7d5177de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "cabe8f3f_16d30a56",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1145459
      },
      "writtenOn": "2020-09-11T15:56:45Z",
      "side": 1,
      "message": "So ",
      "revId": "dfb3f7daa502ab0f5a97bd5dd2d4b4ad7d5177de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "92d0dd23_aec693f9",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1145459
      },
      "writtenOn": "2020-09-11T15:56:45Z",
      "side": 1,
      "message": "Will fix things up as you suggest. \n\nAs far as your comment on the profile start names, the test actually creates a separate CpuProfiler object for each thread so can start each with the same name. I don\u0027t know if this is weird or not, but in my own embedder code I didn\u0027t find any performance difference between a CpuProfiler per profiler or multiple names on a single profiler and I found a CpuProfiler per profile much easier to manage. In fact, I was kind of forced to do this in my own embedder code because I needed different sampling intervals for different profiles (long story).\n\nAnother thought on the OSR code is that we could walk the stack looking for OSR code in EnumerateCompiledFunctions. This could be done fairly efficiently. \n\nI wonder if it even makes sense for OSR code to be in the optimized code hash table -- it was very strange in my playing around seeing a new function compilation force deoptimization of an OSR compilation. If the OSR was still in use on the stack, it would know to deoptimize itself when it hit the modified global property or whatever else causes deoptimization.",
      "parentUuid": "f7faaca6_76cb075b",
      "revId": "dfb3f7daa502ab0f5a97bd5dd2d4b4ad7d5177de",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    }
  ]
}