{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "0b8c01d8_be41c729",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1362925
      },
      "writtenOn": "2022-06-01T21:25:47Z",
      "side": 1,
      "message": "marja@ found an issue with resizable buffers where the different max lengths cause problems. If possible we should make them the same, as the TODO says.\n\nishell@, v8:4153 looks mostly done, but we never actually made the TypedArray and ArrayBuffer max lengths equal. All the V8 tests pass (ignoring the downstream failures in blink and Node). Am I missing anything or is it actually this easy? ðŸ˜Š\n\nIf I\u0027m not missing anything, I\u0027ll fix the downstream issues.",
      "revId": "51e9f14968c04d153d9bbd8be6f5f9de2b22cdff",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "989d82c7_0c6ded69",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1115961
      },
      "writtenOn": "2022-06-02T07:43:42Z",
      "side": 1,
      "message": "Re: \"is it actually this easy\", if there were problems with this approach, I don\u0027t think you\u0027d find them out, in the current form of the CL.\n\nThere are no existing tests that use large TypedArrays in the code base, since they aren\u0027t currently allowed. And this CL doesn\u0027t add any tests. So just changing the constant is probably a NOOP.\n\nI\u0027d guess this is most likely to break when somebody creates a large TypedArray and then it flows to some part of the code which assumes the length is a SMI. Possibly that\u0027d happen in optimized code.\n\nWhat would be the acceptable minimum testing before we can conclude this probably works? At least testing element access + optimizing it for large TypedArrays. Maybe also calling all possible TypedArray.prototype (and Array.prototype?) functions with large TypedArrays, and making sure those also get optimized?\n\nIf you look for v8:4153, there are some comments saying \"support large TypedArrays here\" which sounds like they\u0027re not supported at the moment. They are in various TA.p functions which makes it sound like we\u0027d need testing for all of them to be convinced this works...",
      "parentUuid": "0b8c01d8_be41c729",
      "revId": "51e9f14968c04d153d9bbd8be6f5f9de2b22cdff",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "46c0b033_80639a09",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1183889
      },
      "writtenOn": "2022-06-02T10:16:59Z",
      "side": 1,
      "message": "+1 to Marja\u0027s points, it\u0027s worth going over TODOs first. For example, TypedArrayPrototypeSort\u0027s implementation is not suitable for huge typed arrays at all.\n\nRe testing, we have a --mock-arraybuffer-allocator flag for testing some basic functionality for huge typed arrays but it helps only in very simple scenarios.\nIIRC we discussed this issue with Jakob before, and the idea was to consider throwing an error when TA.p methods see unreasonably huge typed array.\n\nCC\u0027ing Jakob, who had been working on supporting huge typed arrays in the past.",
      "parentUuid": "989d82c7_0c6ded69",
      "revId": "51e9f14968c04d153d9bbd8be6f5f9de2b22cdff",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0fc335f8_adeadb44",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1362925
      },
      "writtenOn": "2022-06-02T14:54:09Z",
      "side": 1,
      "message": "Thanks for the tips, I\u0027ll look into the testing and go through the TODOs. Testing seems pretty gnarly, since we don\u0027t want to actually be allocating sorting 9-petabyte TAs.\n\nI don\u0027t quite understand the Smi point, however, since the hard work was already done to make max TA length 2^32 on 64bit archs, which already exceeds the Smi range. I looked a bit at TF\u0027s assumptions as well but the the TA length has a custom range type already AFAICT.",
      "parentUuid": "46c0b033_80639a09",
      "revId": "51e9f14968c04d153d9bbd8be6f5f9de2b22cdff",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0798983f_d2521346",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1183889
      },
      "writtenOn": "2022-06-02T15:34:01Z",
      "side": 1,
      "message": "I think the main reasons why we didn\u0027t increase the limit back then was inability to test this properly + a lack of demand/motivation from users. \nIIRC the main use case we were caring about was supporting 4GB ArrayBuffers for Wasm.",
      "parentUuid": "0fc335f8_adeadb44",
      "revId": "51e9f14968c04d153d9bbd8be6f5f9de2b22cdff",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "970df4e9_8945a348",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1115935
      },
      "writtenOn": "2022-06-02T22:01:00Z",
      "side": 1,
      "message": "A couple of thoughts:\n\n- On 32-bit platforms, 1 GiB is plenty. It is practically impossible to find 2 GiB of contiguous free _address space_ (even aside from free physical memory) in real-world, non-toy processes. Even finding 256MiB often fails when it\u0027s been a while since renderer startup and address space has experienced fragmentation.\n\n- 64-bit platforms, despite their name, use 48 bits for virtual addresses (of which the kernel typically reserves one for itself); the number of bits for physical addresses depends on specific hardware and in current CPUs typically ranges from 35 (lightweight laptops) to 42 (servers). Additionally, Chrome has a 100 TiB per renderer sandbox limit. So going to 2**53 is absolute overkill, and will be for decades to come (sure, memory grows every year, but look at the past two decades and make an extrapolating guess how that flattening curve will continue!). I\u0027d keep `kMaxSafeInteger` in `v8::internal`.\n\n- One reason against raising V8\u0027s limits too much is that, given sufficient virtual address space, allocations will typically appear to succeed, and only writing to those array elements will cause the kernel to actually reserve the pages and potentially crash the process when that fails. Since \"RangeError\" is a better UX/DX than \"Aw, snap!\", it\u0027s not necessarily a good idea to allow, say, 128 GiB for everyone just because a few expensive workstations might actually have that much memory.\n\n- Keep in mind that a Float64Array with length `N` needs an ArrayBuffer with length `N*8` as its backing store. Perfect equality of limits is hence elusive.\n\n- There should already be no places in the code that attempt to store TypedArray lengths in Smis without checking first. That said, AFAIK there are some builtins that will simply refuse to work on overly large arrays and throw an exception instead. This can already be triggered, so shouldn\u0027t block raising the limit further, but we should address these eventually. (There appears to be very little demand.)\n\n- For testing, we have `--mock-arraybuffer-allocator` (see d8.h/cc), which repeatedly maps the same small memory chunk into a huge address range. It has limitations (Linux only, don\u0027t call `std::sort` on it, expect array elements to alias each other), and you won\u0027t be able to allocate 9 PiB due to virtual address limits (see above).",
      "parentUuid": "0798983f_d2521346",
      "revId": "51e9f14968c04d153d9bbd8be6f5f9de2b22cdff",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "a59ecbb8_5f646f40",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1362925
      },
      "writtenOn": "2022-06-02T22:07:01Z",
      "side": 1,
      "message": "Thanks for the detailed thoughts Jakob!\n\nI should\u0027ve led with the motivation, which is not at all about any particular limit, but just that the TA max length and the AB max length are exactly the same. For resizable buffers, marja@ spotted an issue if the max lengths differ. With resizable buffers, you can have \"length-tracking\" TAs that track the underlying AB\u0027s byte length. So if you have different max lengths, you\u0027d need to throw somewhere for ABs whose max lengths are \u003e TA max lengths. Otherwise, if you have e.g. a length-tracking `Int8Array`, resizes can make it exceed the max TA length. That seems kind of gross if we can make the max lengths the same, whatever that is.",
      "parentUuid": "970df4e9_8945a348",
      "revId": "51e9f14968c04d153d9bbd8be6f5f9de2b22cdff",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "34291286_09282622",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1362925
      },
      "writtenOn": "2022-06-02T22:07:39Z",
      "side": 1,
      "message": "Oops, butchered the last sentence: that seems kind of gross. If we can make the max lengths the same, whatever that is, then we can avoid having to throw somewhere.",
      "parentUuid": "a59ecbb8_5f646f40",
      "revId": "51e9f14968c04d153d9bbd8be6f5f9de2b22cdff",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "11d71906_6aab0a07",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1362925
      },
      "writtenOn": "2022-06-02T22:21:23Z",
      "side": 1,
      "message": "Given all of this, it sounds like we could also _lower_ the max AB length to be 2^32 instead? I wonder if there are uses of ABs \u003e 4G.",
      "parentUuid": "34291286_09282622",
      "revId": "51e9f14968c04d153d9bbd8be6f5f9de2b22cdff",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "aeb63ccf_8cda2a2d",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1115935
      },
      "writtenOn": "2022-06-03T09:07:56Z",
      "side": 1,
      "message": "I don\u0027t think there can be any such uses yet, because there\u0027s no way to construct larger ABs.\n- Wasm Memories are capped to 4GiB currently (though Clemens is looking into raising that to 8 or possibly 16 GiB for \"wasm64\", so capping ABs to 4 GiB is not an option going forward).\n- PartitionAlloc won\u0027t give you more than ~2.1 GiB (if I recall the limit correctly) for direct `new ArrayBuffer(N)` construction.\nThat said, I\u0027m not sure about Node and other non-Chrome embedders.",
      "parentUuid": "11d71906_6aab0a07",
      "revId": "51e9f14968c04d153d9bbd8be6f5f9de2b22cdff",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "80023660_6945df7c",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1115961
      },
      "writtenOn": "2022-06-03T09:30:35Z",
      "side": 1,
      "message": "Re: \"I don\u0027t think there can be any such uses yet, because there\u0027s no way to construct larger ABs.\"\n\nIt\u0027s currently possible to construct a large buffer but use TAs to view only a portion of it at a time.",
      "parentUuid": "aeb63ccf_8cda2a2d",
      "revId": "51e9f14968c04d153d9bbd8be6f5f9de2b22cdff",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}